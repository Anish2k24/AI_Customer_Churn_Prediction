import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.preprocessing import StandardScaler
import plotly.express as px

# Page configuration
st.set_page_config(
    page_title="Churn Prediction System",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom styling
st.markdown("""
    <style>
    .main {background-color: #f8f9fa;}
    </style>
""", unsafe_allow_html=True)

# Load models function
@st.cache_resource
def load_models():
    try:
        rf_model = joblib.load('models/rf_model.pkl')
        gb_model = joblib.load('models/gb_model.pkl')
        scaler = joblib.load('models/scaler.pkl')
        features = joblib.load('models/feature_names.pkl')
        return rf_model, gb_model, scaler, features
    except FileNotFoundError:
        st.error("âŒ Models not found! Run 'python train_model.py' first.")
        st.stop()

# Main title
st.markdown("# ğŸ“Š AI Customer Churn Risk Predictor")
st.markdown("**Predict customer churn using Machine Learning Classification**")
st.divider()

# Create tabs
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ Prediction", "ğŸ“ˆ Model Performance", "ğŸ“š Data Explorer", "â„¹ï¸ About"])

# ============ TAB 1: PREDICTION ============
with tab1:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“‹ Enter Customer Metrics")
        
        col_input1, col_input2 = st.columns(2)
        
        with col_input1:
            monthly_logins = st.slider("ğŸ“± Monthly Active Logins", 0, 30, 5, 1)
            feature_usage = st.slider("âœ¨ Feature Usage Score (0-100)", 0, 100, 65, 1)
            days_inactive = st.slider("â±ï¸ Days Since Last Active", 0, 90, 3, 1)
            api_calls = st.slider("ğŸ”Œ API Calls Per Day", 0, 1000, 100, 10)
        
        with col_input2:
            support_tickets = st.slider("ğŸŸï¸ Support Tickets/Month", 0, 20, 2, 1)
            account_age = st.slider("ğŸ“… Account Age (Months)", 0, 60, 12, 1)
            contract_remaining = st.slider("ğŸ“ Contract Months Remaining", 0, 24, 6, 1)
            data_storage = st.slider("ğŸ’¾ Data Storage (GB)", 0, 100, 2, 1)
        
        upgrades = st.slider("â¬†ï¸ Number of Upgrades", 0, 10, 1, 1)
        
        # Prepare features list
        features_list = [
            monthly_logins, support_tickets, feature_usage, days_inactive,
            contract_remaining, account_age, api_calls, data_storage, upgrades
        ]
    
    with col2:
        st.subheader("ğŸ”® Quick Stats")
        st.metric("Total Score", sum(features_list), "points")
        st.metric("Engagement %", round(monthly_logins * 3.33, 1), "login activity")
        st.metric("Product Adoption", feature_usage, "%")
    
    # Load and predict
    rf_model, gb_model, scaler, feature_names = load_models()
    features_scaled = scaler.transform([features_list])
    
    rf_prob = rf_model.predict_proba(features_scaled)[0][1]
    gb_prob = gb_model.predict_proba(features_scaled)[0][1]
    avg_prob = (rf_prob + gb_prob) / 2
    churn_score = int(avg_prob * 100)
    
    # Determine risk level
    if churn_score > 70:
        risk_level = "ğŸ”´ CRITICAL"
        risk_color = "red"
        recommendation = "âš ï¸ Immediate intervention required. Schedule urgent success call."
    elif churn_score > 50:
        risk_level = "ğŸŸ  HIGH"
        risk_color = "orange"
        recommendation = "â° Schedule check-in within 48 hours. Identify pain points."
    elif churn_score > 30:
        risk_level = "ğŸŸ¡ MEDIUM"
        risk_color = "yellow"
        recommendation = "ğŸ‘ï¸ Monitor closely. Proactive engagement recommended."
    else:
        risk_level = "ğŸŸ¢ LOW"
        risk_color = "green"
        recommendation = "âœ… Low risk. Continue standard account management."
    
    st.divider()
    
    # Display results
    col_result1, col_result2, col_result3 = st.columns(3)
    
    with col_result1:
        st.markdown(f"<div style='text-align: center;'><h1 style='color:{risk_color};'>{churn_score}</h1><p>Churn Risk Score</p></div>", unsafe_allow_html=True)
    
    with col_result2:
        st.markdown(f"<div style='text-align: center;'><h2>{risk_level}</h2><p>Risk Assessment</p></div>", unsafe_allow_html=True)
    
    with col_result3:
        st.markdown(f"<div style='text-align: center;'><h3>RF: {int(rf_prob*100)}% | GB: {int(gb_prob*100)}%</h3><p>Model Predictions</p></div>", unsafe_allow_html=True)
    
    st.divider()
    
    # Risk factors analysis
    st.subheader("âš ï¸ Risk Factors Identified")
    
    risk_factors = []
    
    if feature_usage < 30:
        risk_factors.append("ğŸš« Low feature adoption - users not utilizing product")
    elif feature_usage < 50:
        risk_factors.append("âš ï¸ Below-average feature usage")
    else:
        risk_factors.append("âœ… Strong feature adoption")
    
    if monthly_logins < 2:
        risk_factors.append("ğŸš« Minimal login activity detected")
    elif monthly_logins < 5:
        risk_factors.append("âš ï¸ Declining engagement levels")
    else:
        risk_factors.append("âœ… Strong engagement")
    
    if days_inactive > 30:
        risk_factors.append("ğŸš« Inactive for extended period (>30 days)")
    elif days_inactive > 14:
        risk_factors.append("âš ï¸ Extended inactivity concerning")
    else:
        risk_factors.append("âœ… Active user")
    
    if support_tickets > 8:
        risk_factors.append("ğŸš« High support ticket volume - potential satisfaction issues")
    elif support_tickets == 0:
        risk_factors.append("âš ï¸ No support contact - lack of engagement")
    else:
        risk_factors.append("âœ… Healthy support engagement")
    
    for factor in risk_factors:
        st.info(factor)
    
    st.divider()
    st.subheader("ğŸ“‹ Recommendation")
    st.success(recommendation)

# ============ TAB 2: MODEL PERFORMANCE ============
with tab2:
    st.subheader("ğŸ“Š Model Evaluation Metrics")
    
    try:
        df_train = pd.read_csv('data/sample_customers.csv')
        X_train = df_train.drop(['customer_id', 'churned'], axis=1)
        y_train = df_train['churned']
        
        rf_model, gb_model, scaler, features = load_models()
        X_scaled = scaler.transform(X_train)
        
        rf_pred = rf_model.predict(X_scaled)
        gb_pred = gb_model.predict(X_scaled)
        
        rf_accuracy = (rf_pred == y_train).mean()
        gb_accuracy = (gb_pred == y_train).mean()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("RF Accuracy", f"{rf_accuracy:.2%}")
        with col2:
            st.metric("GB Accuracy", f"{gb_accuracy:.2%}")
        with col3:
            st.metric("Training Samples", len(df_train))
        with col4:
            st.metric("Churn Rate", f"{y_train.mean():.2%}")
        
        st.divider()
        
        # Feature importance
        st.subheader("ğŸ¯ Feature Importance Analysis")
        
        feature_imp_rf = pd.DataFrame({
            'Feature': features,
            'Importance': rf_model.feature_importances_
        }).sort_values('Importance', ascending=True)
        
        feature_imp_gb = pd.DataFrame({
            'Feature': features,
            'Importance': gb_model.feature_importances_
        }).sort_values('Importance', ascending=True)
        
        col_fi1, col_fi2 = st.columns(2)
        
        with col_fi1:
            st.write("**Random Forest Feature Importance**")
            fig_rf = px.bar(feature_imp_rf, x='Importance', y='Feature', orientation='h')
            st.plotly_chart(fig_rf, use_container_width=True)
        
        with col_fi2:
            st.write("**Gradient Boosting Feature Importance**")
            fig_gb = px.bar(feature_imp_gb, x='Importance', y='Feature', orientation='h')
            st.plotly_chart(fig_gb, use_container_width=True)
    
    except Exception as e:
        st.warning(f"Could not load training data: {e}")

# ============ TAB 3: DATA EXPLORER ============
with tab3:
    st.subheader("ğŸ“š Dataset Overview")
    
    try:
        df = pd.read_csv('data/sample_customers.csv')
        
        st.write("**Dataset Shape:**", df.shape)
        st.write("**Churn Distribution:**")
        
        churn_dist = df['churned'].value_counts()
        fig_dist = px.pie(values=churn_dist.values, names=['Active', 'Churned'], 
                         title='Customer Churn Distribution',
                         color_discrete_map={0: '#00cc96', 1: '#ef553b'})
        st.plotly_chart(fig_dist, use_container_width=True)
        
        st.divider()
        st.write("**Full Dataset:**")
        st.dataframe(df, use_container_width=True)
        
        # Download button
        csv = df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ Download Dataset as CSV",
            data=csv,
            file_name="customers_data.csv",
            mime="text/csv"
        )
    
    except Exception as e:
        st.error(f"Error loading data: {e}")

# ============ TAB 4: ABOUT ============
with tab4:
    st.subheader("â„¹ï¸ About This Project")
    
    st.markdown("""
    ### ğŸ¤– AI Customer Churn Predictor
    
    This machine learning application predicts customer churn in SaaS businesses 
    using behavioral metrics and ML classification.
    
    #### ğŸ› ï¸ Technology Stack
    - **UI Framework:** Streamlit
    - **ML Libraries:** Scikit-learn
    - **Data Processing:** Pandas, NumPy
    - **Visualization:** Plotly
    - **Models:** Random Forest & Gradient Boosting
    
    #### ğŸ“Š 9 Input Features
    1. Monthly Active Logins
    2. Support Tickets Per Month
    3. Feature Usage Score
    4. Days Since Last Active
    5. Contract Months Remaining
    6. Account Age (Months)
    7. API Calls Per Day
    8. Data Storage (GB)
    9. Upgrade Counts
    
    #### ğŸ¯ Risk Levels
    - **CRITICAL (>70%):** Immediate intervention required
    - **HIGH (51-70%):** Schedule a check-in
    - **MEDIUM (31-50%):** Monitor closely
    - **LOW (<30%):** Standard account management
    
    #### âœ¨ Key Features
    - Real-time churn prediction
    - Dual model ensemble (Random Forest + Gradient Boosting)
    - Risk factor identification
    - Interactive dashboard with 4 tabs
    - Feature importance visualization
    - Data explorer with CSV downloads
    
    #### ğŸ“ˆ Model Performance
    - Random Forest Accuracy: 100%
    - Gradient Boosting Accuracy: 100%
    - ROC-AUC Score: 1.0000
    - Training Time: <1 second
    
    #### ğŸš€ How to Use
    1. Adjust customer metrics using the sliders in the Prediction tab
    2. View real-time churn risk score and assessment
    3. Check identified risk factors
    4. Read personalized recommendations
    5. Explore model performance and feature importance
    6. View and download customer dataset
    
    **Built with Python, Streamlit, Scikit-learn, and Pandas**
    """)