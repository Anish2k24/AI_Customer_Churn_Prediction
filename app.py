import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.preprocessing import StandardScaler
import plotly.express as px

# Config of the page
st.set_page_config(
    page_title="Churn Prediction System",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .main {background-color: #f8f9fa;}
    </style>
""", unsafe_allow_html=True)

 # models function loading
@st.cache_resource
def load_models():
    try:
        rf_model = joblib.load('models/rf_model.pkl')
        gb_model = joblib.load('models/gb_model.pkl')
        scaler = joblib.load('models/scaler.pkl')
        features = joblib.load('models/feature_names.pkl')
        return rf_model, gb_model, scaler, features
    except FileNotFoundError:
        st.error(" Models not found! Run 'python train_model.py' first.")
        st.stop()

# Main title
st.markdown("#  AI Customer Churn Risk Predictor")
st.markdown("**Predict customer churn using Machine Learning Classification**")
st.divider()

# tabs created
tab1, tab2, tab3, tab4 = st.tabs([" Prediction", " Model Performance", " Data Explorer", " About"])

# 1st tab: Prediction 
with tab1:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(" Enter Customer Metrics")
        
        col_input1, col_input2 = st.columns(2)
        
        with col_input1:
            monthly_logins = st.slider("üì± Monthly Active Logins", 0, 30, 5, 1)
            feature_usage = st.slider("‚ú® Feature Usage Score (0-100)", 0, 100, 65, 1)
            days_inactive = st.slider("‚è±Ô∏è Days Since Last Active", 0, 90, 3, 1)
            api_calls = st.slider("üîå API Calls Per Day", 0, 1000, 100, 10)
        
        with col_input2:
            support_tickets = st.slider(" Support Tickets/Month", 0, 20, 2, 1)
            account_age = st.slider(" Account Age (Months)", 0, 60, 12, 1)
            contract_remaining = st.slider(" Contract Months Remaining", 0, 24, 6, 1)
            data_storage = st.slider(" Data Storage (GB)", 0, 100, 2, 1)
        
        upgrades = st.slider(" Number of Upgrades", 0, 10, 1, 1)
        
        # Preparing the features list
        features_list = [
            monthly_logins, support_tickets, feature_usage, days_inactive,
            contract_remaining, account_age, api_calls, data_storage, upgrades
        ]
    
    with col2:
        st.subheader(" Quick Stats")
        st.metric("Total Score", sum(features_list), "points")
        st.metric("Engagement %", round(monthly_logins * 3.33, 1), "login activity")
        st.metric("Product Adoption", feature_usage, "%")
    
    # Loading and prediction
    rf_model, gb_model, scaler, feature_names = load_models()
    features_scaled = scaler.transform([features_list])
    
    rf_prob = rf_model.predict_proba(features_scaled)[0][1]
    gb_prob = gb_model.predict_proba(features_scaled)[0][1]
    avg_prob = (rf_prob + gb_prob) / 2
    churn_score = int(avg_prob * 100)
    
    # Determine risk level
    if churn_score > 70:
        risk_level = "üî¥ Critical level"
        risk_color = "red"
        recommendation = " Immediate intervention required. Schedule urgent success call."
    elif churn_score > 50:
        risk_level = "üü† Higher level"
        risk_color = "orange"
        recommendation = "‚è∞ Schedule check-in within 48 hours. Identify pain points."
    elif churn_score > 30:
        risk_level = "üü° Moderate level"
        risk_color = "yellow"
        recommendation = "üëÅÔ∏è Monitor closely. Proactive engagement recommended."
    else:
        risk_level = "üü¢ Lower level"
        risk_color = "green"
        recommendation = " Low risk. Continue standard account management."
    
    st.divider()
    
    # Displaying results
    col_result1, col_result2, col_result3 = st.columns(3)
    
    with col_result1:
        st.markdown(f"<div style='text-align: center;'><h1 style='color:{risk_color};'>{churn_score}</h1><p>Churn Risk Score</p></div>", unsafe_allow_html=True)
    
    with col_result2:
        st.markdown(f"<div style='text-align: center;'><h2>{risk_level}</h2><p>Risk Assessment</p></div>", unsafe_allow_html=True)
    
    with col_result3:
        st.markdown(f"<div style='text-align: center;'><h3>RF: {int(rf_prob*100)}% | GB: {int(gb_prob*100)}%</h3><p>Model Predictions</p></div>", unsafe_allow_html=True)
    
    st.divider()
    
    # Risk factors analysis
    st.subheader(" Risk Factors Identified")
    
    risk_factors = []
    
    if feature_usage < 30:
        risk_factors.append(" Low feature adoption - users not utilizing product")
    elif feature_usage < 50:
        risk_factors.append(" Below-average feature usage")
    else:
        risk_factors.append(" Strong feature adoption")
    
    if monthly_logins < 2:
        risk_factors.append(" Minimal login activity detected")
    elif monthly_logins < 5:
        risk_factors.append(" Declining engagement levels")
    else:
        risk_factors.append(" Strong engagement")
    
    if days_inactive > 30:
        risk_factors.append(" Inactive for extended period (>30 days)")
    elif days_inactive > 14:
        risk_factors.append(" Extended inactivity concerning")
    else:
        risk_factors.append(" Active user")
    
    if support_tickets > 8:
        risk_factors.append(" High support ticket volume - potential satisfaction issues")
    elif support_tickets == 0:
        risk_factors.append(" No support contact - lack of engagement")
    else:
        risk_factors.append(" Healthy support engagement")
    
    for factor in risk_factors:
        st.info(factor)
    
    st.divider()
    st.subheader(" Recommendation")
    st.success(recommendation)

# 2nd tab: Model Performance
with tab2:
    st.subheader(" Model Evaluation Metrics")
    
    try:
        df_train = pd.read_csv('data/sample_customers.csv')
        X_train = df_train.drop(['customer_id', 'churned'], axis=1)
        y_train = df_train['churned']
        
        rf_model, gb_model, scaler, features = load_models()
        X_scaled = scaler.transform(X_train)
        
        rf_pred = rf_model.predict(X_scaled)
        gb_pred = gb_model.predict(X_scaled)
        
        rf_accuracy = (rf_pred == y_train).mean()
        gb_accuracy = (gb_pred == y_train).mean()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("RF Accuracy", f"{rf_accuracy:.2%}")
        with col2:
            st.metric("GB Accuracy", f"{gb_accuracy:.2%}")
        with col3:
            st.metric("Training Samples", len(df_train))
        with col4:
            st.metric("Churn Rate", f"{y_train.mean():.2%}")
        
        st.divider()
        
        # Feature importance
        st.subheader(" Feature Importance Analysis")
        
        feature_imp_rf = pd.DataFrame({
            'Feature': features,
            'Importance': rf_model.feature_importances_
        }).sort_values('Importance', ascending=True)
        
        feature_imp_gb = pd.DataFrame({
            'Feature': features,
            'Importance': gb_model.feature_importances_
        }).sort_values('Importance', ascending=True)
        
        col_fi1, col_fi2 = st.columns(2)
        
        with col_fi1:
            st.write("**Random Forest Feature Importance**")
            fig_rf = px.bar(feature_imp_rf, x='Importance', y='Feature', orientation='h')
            st.plotly_chart(fig_rf, use_container_width=True)
        
        with col_fi2:
            st.write("**Gradient Boosting Feature Importance**")
            fig_gb = px.bar(feature_imp_gb, x='Importance', y='Feature', orientation='h')
            st.plotly_chart(fig_gb, use_container_width=True)
    
    except Exception as e:
        st.warning(f"Could not load training data: {e}")

# 3rd tab: Data Explorer
with tab3:
    st.subheader(" Dataset Overview")
    
    try:
        df = pd.read_csv('data/sample_customers.csv')
        
        st.write("**Dataset Shape:**", df.shape)
        st.write("**Churn Distribution:**")
        
        churn_dist = df['churned'].value_counts()
        fig_dist = px.pie(values=churn_dist.values, names=['Active', 'Churned'], 
                         title='Customer Churn Distribution',
                         color_discrete_map={0: '#00cc96', 1: '#ef553b'})
        st.plotly_chart(fig_dist, use_container_width=True)
        
        st.divider()
        st.write("**Full Dataset:**")
        st.dataframe(df, use_container_width=True)
        
        # Download button
        csv = df.to_csv(index=False)
        st.download_button(
            label=" Download Dataset as CSV",
            data=csv,
            file_name="customers_data.csv",
            mime="text/csv"
        )
    
    except Exception as e:
        st.error(f"Error loading data: {e}")

# 4th tab: About section
with tab4:
    st.subheader(" About This Project")
    
    st.markdown("""
    ###  AI Customer Churn Predictor
    
    This machine learning application predicts customer churn in SaaS businesses 
    using behavioral metrics and ML classification.
    
    ####  Technology Stack
    - **UI Framework:** Streamlit
    - **ML Libraries:** Scikit-learn
    - **Data Processing:** Pandas, NumPy
    - **Visualization:** Plotly
    - **Models:** Random Forest & Gradient Boosting
    
    #### 9 Input Features
    1. Monthly Active Logins
    2. Support Tickets Per Month
    3. Feature Usage Score
    4. Days Since Last Active
    5. Contract Months Remaining
    6. Account Age (Months)
    7. API Calls Per Day
    8. Data Storage (GB)
    9. Upgrade Counts
    
    #### Risk Levels
    - **CRITICAL (>70%):** Immediate intervention required
    - **HIGH (51-70%):** Schedule a check-in
    - **MEDIUM (31-50%):** Monitor closely
    - **LOW (<30%):** Standard account management
    
    #### Key Features
    - Real-time churn prediction
    - Dual model ensemble (Random Forest + Gradient Boosting)
    - Risk factor identification
    - Interactive dashboard with 4 tabs
    - Feature importance visualization
    - Data explorer with CSV downloads
    
    ####  Model Performance
    - Random Forest Accuracy: 100%
    - Gradient Boosting Accuracy: 100%
    - ROC-AUC Score: 1.0000
    - Training Time: <1 second
    
    #### How to Use
    1. Adjust customer metrics using the sliders in the Prediction tab
    2. View real-time churn risk score and assessment
    3. Check identified risk factors
    4. Read personalized recommendations
    5. Explore model performance and feature importance
    6. View and download customer dataset
    
    **Built with Python, Streamlit, Scikit-learn, and Pandas**
    """)